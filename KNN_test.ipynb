{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7UNDnxNQtrBX8q70115qH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinnyfruit/Data_Science_Project/blob/main/KNN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t51EXAxNcTwq",
        "outputId": "9ea1c32e-f180-42dc-d6cd-761127ecdb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3273542600896861\n",
            "0.3542600896860987\n",
            "0.28699551569506726\n",
            "0.273542600896861\n",
            "0.3721973094170404\n",
            "0.30493273542600896\n",
            "0.30493273542600896\n",
            "0.3273542600896861\n",
            "0.273542600896861\n",
            "0.3542600896860987\n",
            "0.2645739910313901\n",
            "0.33183856502242154\n",
            "0.3632286995515695\n",
            "0.29596412556053814\n",
            "0.34977578475336324\n",
            "0.3452914798206278\n",
            "0.34080717488789236\n",
            "0.2645739910313901\n",
            "0.35874439461883406\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import random\n",
        "\n",
        "#before predict target values through model, preprocess dataframe\n",
        "def prepare_df(df_original):\n",
        "  #create a dataframe without unnecessary features \n",
        "  df=df_original.drop(['Stress busters','Time utilized','Do you find yourself more connected with your family, close friends , relatives  ?'],axis=1)\n",
        "  df=(df.drop('Time spent on TV',axis=1).join(df['Time spent on TV'].apply(pd.to_numeric,errors='coerce')))\n",
        "  df=df.replace({'Excellent':5,'Good':4,'Average':3,'Poor':2,'Very poor':1})\n",
        "  df.dropna(inplace=True)\n",
        "  #seperate taret values\n",
        "  #X=df.iloc[:,[2,3,6,7,8,9,10,13]]\n",
        "  grid=[2,3,6,7,8,9,10,13]\n",
        " \n",
        "  alist=[]        \n",
        "  count=random.randint(1,8)                  # 뽑은 a를 넣어 중복 방지해주는 리스트         \n",
        "  for i in range(count):\n",
        "    a = random.randint(0,7)       \n",
        "    while a in alist :              # a가 이미 뽑은 리스트에 있을 때까지 다시 뽑자\n",
        "      a = random.randint(0,7)\n",
        "    alist.append(grid[a]) # 새로운 a 값을 리스트에 추가\n",
        "\n",
        "  randX=df.iloc[:,alist]\n",
        "  y=df['Rating of Online Class experience'].values\n",
        "  return df,randX,y\n",
        "\n",
        "\n",
        "#return n features according to its importance\n",
        "def feature_importance(X,y,n):\n",
        "  #feature importance scoring\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  model=ExtraTreesClassifier()\n",
        "  model.fit(X,y)\n",
        "  print(model.feature_importances_[0:n])\n",
        "  feat_importances=pd.Series(model.feature_importances_,index=X.columns)\n",
        "  feat_importances.nlargest(n).plot(kind='barh')\n",
        "  plt.show()\n",
        "  return feat_importances.nlargest(n)\n",
        "\n",
        "def predictScore(df,kfold_n):\n",
        "  kfold=KFold()\n",
        "  df,X,y=prepare_df(df)\n",
        "  score=[]\n",
        "  if(kfold_n<0):\n",
        "    return 0\n",
        "  for train, test in kfold.split(df):\n",
        "    temp=[]\n",
        "    X_train,X_test=X.iloc[train,:],X.iloc[test,:]\n",
        "    y_train,y_test=y[train],y[test]\n",
        "  \n",
        "    knn=KNeighborsClassifier(n_neighbors=(kfold_n+1))\n",
        "    knn.fit(X_train,y_train)\n",
        "    knn.predict(X_test)\n",
        "    temp.append(knn.score(X_test,y_test))\n",
        "  score.append(np.max(temp))\n",
        "  print(np.max(score))\n",
        "    #print('score of knn without hypertuning(with k-fold',kfold_n,'): ',knn.score(X_test,y_test))\n",
        "  \n",
        "df=pd.read_csv('/content/COVID-19 Survey Student Responses (1).csv')\n",
        "\n",
        "for i in range(1,20):\n",
        "  predictScore(df,kfold_n=i)\n"
      ]
    }
  ]
}